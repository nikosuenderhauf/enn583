{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENN583 - Week 3 - Practical: Stereo Vision    \n",
    "\n",
    "In this week's Prac we will explore two stereo vision algorithms available in OpenCV. \n",
    "\n",
    "We will again work with the -- now familiar -- Kitti dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Kitti Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if pykitti is installed, if not use pip to set it up\n",
    "try:\n",
    "    import pykitti\n",
    "except:\n",
    "    !pip install pykitti\n",
    "    import pykitti\n",
    "\n",
    "# Read the dataset sequence we just downloaded\n",
    "basedir = '../kitti'\n",
    "date = '2011_09_26'\n",
    "drive = '0035'\n",
    "\n",
    "# The 'frames' argument is optional - default: None, which loads the whole dataset.\n",
    "# data = pykitti.raw(basedir, date, drive, frames=range(0, 50, 5))\n",
    "data = pykitti.raw(basedir, date, drive)\n",
    "\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get the left and right stereo images from the 10th frame\n",
    "left, right = data.get_rgb(10)\n",
    "left = np.array(left)\n",
    "right = np.array(right)\n",
    "\n",
    "# use plt to show them side by side\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(left, cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(right, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Use the Stereo Block Matcher\n",
    "The simplest stereo matching algorithm is provided by the `StereoBM` class in OpenCV. The cell below demonstrated how to use it.\n",
    "\n",
    "Notice that it expects the left and right image to be grey scale images, so we will have to convert the RBB images first.\n",
    "\n",
    "You can access the documentation of the `StereoBM` here: https://docs.opencv.org/4.7.0/d9/dba/classcv_1_1StereoBM.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and convert to grayscale\n",
    "left, right = data.get_rgb(10)\n",
    "left = cv2.cvtColor(np.array(left), cv2.COLOR_BGR2GRAY)\n",
    "right = cv2.cvtColor(np.array(right), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# use the stereo blockmatcher to get a disparity map\n",
    "stereo = cv2.StereoBM_create(blockSize=15) # this creates the blockmatcher object\n",
    "disparity = stereo.compute(left, right)                     # this computes the disparity map\n",
    "\n",
    "# display the disparity\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(disparity,'gray')\n",
    "plt.title('Disparity Map using block matching')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# what is the range of disparity values?\n",
    "print('Disparity range: ', disparity.min(), ' to ', disparity.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the disparity values range from below -16 to over 1000! We know that they should be in pixels, so what is going on here?\n",
    "\n",
    "OpenCV returns the disparity map scaled by 16, and as a int16 type. To get the real disparity values, we will have to scale it accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the values in `disparity` to pixels\n",
    "if disparity.dtype != np.float32:\n",
    "    disparity = disparity.astype(np.float32) / 16.0\n",
    "\n",
    "# display the disparity\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(disparity,'gray')\n",
    "plt.title('Disparity Map using block matching after scaling')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# what is the range of disparity values?\n",
    "print('Scaled disparity range: ', disparity.min(), ' to ', disparity.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks much better! Now we have the disparity values in pixels. \n",
    "\n",
    "Notice how a negative value of -1 is used to indicate pixels for which no disparity value could be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!\n",
    "Let's explore some parameters of the block matcher.\n",
    "\n",
    "In the cell below, create the stereo matcher with different parameters settings and display the resulting disparity images side by side for better comparison.\n",
    "\n",
    "Change the following paramters:\n",
    "\n",
    " - `blockSize` \n",
    "   - Try different block sizes between 5 and 25. \n",
    "   - Notice that this parameter must be an odd number. Why is that?\n",
    "   - What can you observe as you make the block size smaller or larger?\n",
    "- Uniqueness Ratio\n",
    "  - This is a post processing sep, that filters out pixels with potentially bad disparity estimates.\n",
    "    - A pixel is filtered out if the best matching disparity is not sufficiently better than every other disparity in the search range, by applying a uniqueness ratio test.\n",
    "  - Try changingn this value between 15 and 100, by calling `stereo.setUniquenessRatio()`\n",
    "  - You can see what the current value is with `stereo.getUniquenessRatio()`\n",
    "- Texture Threshold\n",
    "  - This filters out areas that do not have enough texture information for reliable matching.\n",
    "  - You can access it via the functions `stereo.getTextureThreshold()` and `stereo.setTextureThreshold()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and convert to grayscale\n",
    "left, right = data.get_rgb(10)\n",
    "left = cv2.cvtColor(np.array(left), cv2.COLOR_BGR2GRAY)\n",
    "right = cv2.cvtColor(np.array(right), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# YOUR TURN! Change the parameters of the blockmatcher and compare the results\n",
    "\n",
    "# use the stereo blockmatcher to get a disparity map\n",
    "# stereo = cv2.StereoBM_create(...) # try changing the blockSize\n",
    "# stereo.set ...\n",
    "# disparity = stereo.compute(left, right)  \n",
    "\n",
    "\n",
    "# scale the disparity to proper pixel values\n",
    "disparity = disparity.astype(np.float32) / 16.0\n",
    "\n",
    "# plot the disparity map\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(disparity,'gray')\n",
    "plt.title('Disparity Map using block matching')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# what is the range of disparity values?\n",
    "print('Scaled disparity range: ', disparity.min(), ' to ', disparity.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the Semi-Global Matching\n",
    "OpenCV comes with a second implementation for stereo matching, based on the paper \n",
    "`Heiko Hirschmuller. Stereo processing by semiglobal matching and mutual information. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 30(2):328â€“341, 2008.` which is available here: https://core.ac.uk/download/pdf/11134866.pdf\n",
    "\n",
    "This is a more advanced method compared to the simple block matchers, but can be more resource hungry.\n",
    "\n",
    "The OpenCV documentation is at https://docs.opencv.org/4.7.0/d2/d85/classcv_1_1StereoSGBM.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images. This time we do not have to convert them to grayscale, since the algorithm can work directly on RGB\n",
    "left, right = data.get_rgb(10)\n",
    "left = np.array(left)\n",
    "right = np.array(right)\n",
    "\n",
    "# create the Semi-Global Block Matching object\n",
    "stereo = cv2.StereoSGBM_create(blockSize=5, numDisparities=16, mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n",
    "\n",
    "# compute the disparity map\n",
    "disparity = stereo.compute(left, right)\n",
    "\n",
    "# as before, we have to scale the outputs to actual pixel values\n",
    "disparity = disparity.astype(np.float32) / 16.0\n",
    "\n",
    "# display the disparity\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(disparity,'gray')\n",
    "plt.title('Disparity Map using Semi-Global Matching after scaling')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# what is the range of disparity values?\n",
    "print('Scaled disparity range: ', disparity.min(), ' to ', disparity.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!\n",
    "\n",
    "The SGBM is better documented than the simple BM class. Head to https://docs.opencv.org/4.7.0/d2/d85/classcv_1_1StereoSGBM.html#adb7a50ef5f200ad9559e9b0e976cfa59 and check the parameters that can be passed into the constructor. \n",
    "\n",
    "Run a number of experiments comparing the effects of these parameters.\n",
    "\n",
    "Definitely try changing `blockSize` and `numDisparities`, as well as `uniquenessRatio`, `P1` and `P2` (controlling the smoothness).\n",
    "\n",
    "If you set `numDisparities` to a low value (try comparing between 16 and 100), what do you notice? Why do you think this happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Turn!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate 3D coordinates for Interest Points\n",
    "\n",
    "We now have two different ways of establishing the 3D coordinates for points in the image. \n",
    "\n",
    "**Option 1:**\n",
    " - We can calculate the full disparity map and use that to calculate the 3D coordiantes for specific interest points that we find in either the left or right image.\n",
    "\n",
    "\n",
    "**Option 2:**\n",
    " - We can detect interest points in both the left and right image, then match between the left and right points. We then have a \"sparse\" disparity map, meaning we only have disparity information for the matched interest points. This can be used to calculate their 3D coordinates.\n",
    "\n",
    "### Your Turn!\n",
    "Implement both options and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== OPTION 1 ======\n",
    "\n",
    "# load images\n",
    "\n",
    "# claculate disparity map\n",
    "\n",
    "# find interest points in left image\n",
    "\n",
    "# calculate 3D coordinates of interest points based on disparity map\n",
    "\n",
    "\n",
    "\n",
    "# ====== OPTION 2 ======\n",
    "\n",
    "# load images\n",
    "\n",
    "# find interest points (and their descriptors) in left and right image\n",
    "\n",
    "# match interest points between left and right image\n",
    "\n",
    "# use difference in v-coordinates of matched interest points to calculate sparse disparity map\n",
    "\n",
    "# calculate 3D coordinates of interest points \n",
    "\n",
    "\n",
    "# ====== Comparison ======\n",
    "\n",
    "# Are the results of the two options the same? \n",
    "\n",
    "# If not, what reasons do you suspect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enn583",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
