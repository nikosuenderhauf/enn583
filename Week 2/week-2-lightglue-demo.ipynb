{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGlue Demo\n",
    "\n",
    "This notebook demonstrates how you can install and use LightGlue, a 2023 library for feature point matching. Check their GitHub page for more details and a link to the paper: https://github.com/cvg/LightGlue\n",
    "\n",
    "This Demo uses the SuperPoint detector from the paper that you read for your Assessment 1. LightGlue also comes with an implementation of DISK, another learned detector. You can use LightGlue with other descriptors too, e.g. SIFT.\n",
    "\n",
    "Besides using LightGlue, this notebook also demonstrates how you can quite easily install and use any other library that is available via pip / git on the Jupyter server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install LightGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this clones the repo and installs the dependencies\n",
    "from pathlib import Path\n",
    "if Path.cwd().name != 'LightGlue':\n",
    "  !git clone --quiet https://github.com/cvg/LightGlue/\n",
    "  %cd LightGlue\n",
    "  !pip install --progress-bar off --quiet -e .\n",
    "    \n",
    "from lightglue import LightGlue, SuperPoint, DISK\n",
    "from lightglue.utils import load_image, rbd\n",
    "from lightglue import viz2d\n",
    "import torch\n",
    "torch.set_grad_enabled(False);\n",
    "images = Path('assets')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 'mps', 'cpu'\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Access to the Kitti Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import pykitti\n",
    "\n",
    "basedir = '../kitti'\n",
    "date = '2011_09_26'\n",
    "drive = '0035'\n",
    "\n",
    "# The 'frames' argument is optional - default: None, which loads the whole dataset.\n",
    "# Calibration, timestamps, and IMU data are read automatically. \n",
    "# Camera and velodyne data are available via properties that create generators\n",
    "# when accessed, or through getter methods that provide random access.\n",
    "# data = pykitti.raw(basedir, date, drive, frames=range(0, 50, 5))\n",
    "data = pykitti.raw(basedir, date, drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract SuperPoints and use LightGlue to match them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we will use SuperPoint as the feature extractor\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "matcher = LightGlue(features='superpoint').eval().to(device)\n",
    "\n",
    "\n",
    "# read images from Kitti\n",
    "image0, image1 = data.get_rgb(10)\n",
    "\n",
    "# we have to convert the images into the proper format for pytorch\n",
    "image0 = torchvision.transforms.functional.pil_to_tensor(image0).type(torch.FloatTensor)/255\n",
    "image1 = torchvision.transforms.functional.pil_to_tensor(image1).type(torch.FloatTensor)/255\n",
    "\n",
    "# extract features and match them\n",
    "feats0 = extractor.extract(image0.to(device))\n",
    "feats1 = extractor.extract(image1.to(device))\n",
    "matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "\n",
    "kpts0, kpts1, matches = feats0['keypoints'], feats1['keypoints'], matches01['matches']\n",
    "m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "\n",
    "# visualise the matches\n",
    "axes = viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_matches(m_kpts0, m_kpts1, color='lime', lw=0.2)\n",
    "viz2d.add_text(0, f'Stop after {matches01[\"stop\"]} layers', fs=20)\n",
    "\n",
    "kpc0, kpc1 = viz2d.cm_prune(matches01['prune0']), viz2d.cm_prune(matches01['prune1'])\n",
    "viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_keypoints([kpts0, kpts1], colors=[kpc0, kpc1], ps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enn583",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
