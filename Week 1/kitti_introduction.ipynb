{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the Kitti Dataset\n",
    "\n",
    "The Kitti dataset is a famous and widely-used dataset in computer vision and robotic vision. It many Gigabytes of recorded images from various cameras, GPS, LIDAR, and IMU sensors. This data has been recorded from a car, and contains scenes from cities, residential areas, rural, etc.\n",
    "\n",
    "We encourage you to read more about it on their [website](https://www.cvlibs.net/datasets/kitti/) and in the [dataset paper](https://www.cvlibs.net/publications/Geiger2013IJRR.pdf).\n",
    "\n",
    "This notebook shows you how to access the sequences you will be working with for your Pracs and Assignment 2 of ENN583. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a first sequence\n",
    "\n",
    "Let's create a new directory, download and unztip one of the smaller sequences \n",
    "This will download around 500MB of data.\n",
    "\n",
    "**Important:** You only have to execute this *once*, and then you can comment it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../kitti\n",
    "!cd ../kitti && curl -O https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_26_drive_0035/2011_09_26_drive_0035_sync.zip\n",
    "!cd ../kitti && curl -O https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_26_calib.zip\n",
    "!cd ../kitti && unzip -o '*.zip'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyKitti package provides convenient functions to access the dataset without having to write code to parse the file structure ourseles.\n",
    "\n",
    "Notice how we install it on the fly with pip in case it cannot be imported at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pykitti\n",
    "except:\n",
    "    !pip install pykitti\n",
    "    import pykitti\n",
    "\n",
    "# Read the dataset sequence we just downloaded\n",
    "basedir = '../kitti'\n",
    "date = '2011_09_26'\n",
    "drive = '0035'\n",
    "\n",
    "# The 'frames' argument is optional - default: None, which loads the whole dataset.\n",
    "# data = pykitti.raw(basedir, date, drive, frames=range(0, 50, 5))\n",
    "data = pykitti.raw(basedir, date, drive)\n",
    "\n",
    "\n",
    "# We now have access to the following information:\n",
    "\n",
    "# dataset.calib:         Calibration data are accessible as a named tuple\n",
    "# dataset.timestamps:    Timestamps are parsed into a list of datetime objects\n",
    "# dataset.oxts:          List of OXTS packets and 6-dof poses as named tuples\n",
    "# dataset.camN:          Returns a generator that loads individual images from camera N\n",
    "# dataset.get_camN(idx): Returns the image from camera N at idx  \n",
    "# dataset.gray:          Returns a generator that loads monochrome stereo pairs (cam0, cam1)\n",
    "# dataset.get_gray(idx): Returns the monochrome stereo pair at idx  \n",
    "# dataset.rgb:           Returns a generator that loads RGB stereo pairs (cam2, cam3)\n",
    "# dataset.get_rgb(idx):  Returns the RGB stereo pair at idx  \n",
    "# dataset.velo:          Returns a generator that loads velodyne scans as [x,y,z,reflectance]\n",
    "# dataset.get_velo(idx): Returns the velodyne scan at idx  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples of how to use this datastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import spatialmath as sm\n",
    "%matplotlib inline\n",
    "\n",
    "# this is how we can access a stereo pair of images\n",
    "left, right = data.get_rgb(10)\n",
    "\n",
    "print(f'The images are stored as a {type(left)}')\n",
    "\n",
    "# data.cam0 and data.cam1 are the left and right grayscale stereo pair\n",
    "# data.cam2 and data.cam3 are the left and right RGB stereo pair\n",
    "\n",
    "# we can also iterate through the dataset\n",
    "# notice how we convert the PIL image into a OpenCV image\n",
    "for left_rgb in data.cam2:\n",
    "    img = cv2.cvtColor(np.array(left_rgb), cv2.COLOR_RGB2BGR)    \n",
    "    # now do something with the image ...\n",
    "\n",
    "# let's access the ground truth pose for each frame\n",
    "print(data.oxts[0].T_w_imu) # the pose of the first frame\n",
    "\n",
    "# these are compatible with the spatialmath SE3 class:\n",
    "T = sm.SE3(data.oxts[0].T_w_imu)\n",
    "print(T)\n",
    "\n",
    "traj = []\n",
    "for oxts in data.oxts:\n",
    "    traj.append(sm.SE3(oxts.T_w_imu))\n",
    "\n",
    "# let's plot the trajectory\n",
    "plt.plot([T.t[0] for T in traj], [T.t[1] for T in traj])\n",
    "plt.grid()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enn583",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
